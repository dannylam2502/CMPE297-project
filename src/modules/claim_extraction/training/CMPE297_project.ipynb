{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize\n",
        "!pip install dataclasses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEeR0Pvxjp7r",
        "outputId": "0fa4703d-b3a2-4a2c-cd59-51a77d860b0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.12/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.5.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.7.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.12/dist-packages (0.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import Dict, Any, List, Tuple, Set, Literal\n",
        "from datetime import datetime, timedelta\n",
        "from dataclasses import dataclass, field\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "dKVd0M9_um_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VerdictType = Literal[\"Supported\", \"Refuted\", \"Not enough evidence\", \"Contested\"]\n",
        "class LLMInterface: pass\n",
        "class ModelInterface:\n",
        "    def predict(self, inputs: List[Tuple[str, str]]) -> List[Tuple[float, float, float]]:\n",
        "        \"\"\"Stub for NLI model prediction.\"\"\"\n",
        "        pass\n",
        "\n",
        "class SourcePassage:\n",
        "    def __init__(self, content, domain, relevance_score, published_at):\n",
        "        self.content = content\n",
        "        self.domain = domain\n",
        "        self.relevance_score = relevance_score\n",
        "        self.published_at = published_at\n",
        "class Citation:\n",
        "    def __init__(self, passage):\n",
        "        self.passage = passage\n",
        "@dataclass\n",
        "class ClaimCheckResult:\n",
        "    passage: SourcePassage\n",
        "    entail_prob: float = 0.0\n",
        "    contradict_prob: float = 0.0\n",
        "    neutral_prob: float = 0.0\n",
        "    recency_weight: float = 0.0\n",
        "    numeric_date_ok: bool = False\n",
        "@dataclass\n",
        "class FactCheckFeatures:\n",
        "    entail_max: float\n",
        "    entail_mean3: float\n",
        "    contradict_max: float\n",
        "    agree_domain_count: int\n",
        "    releliance_score_avg: float\n",
        "    recency_weight_max: float\n",
        "    contest_score: float = 0.0\n",
        "@dataclass\n",
        "class FactCheckResult:\n",
        "    claim: str\n",
        "    verdict: VerdictType\n",
        "    score: int\n",
        "    citations: List[Citation]\n",
        "    features: FactCheckFeatures\n"
      ],
      "metadata": {
        "id": "nbH50cI7uqiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# --- REAL NLI MODEL (with the required .predict() method) ---\n",
        "# ==============================================================================\n",
        "NLI_LABELS = [\"contradiction\", \"neutral\", \"entailment\"]\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers.utils import logging as hf_logging\n",
        "\n",
        "# Suppress heavy logging\n",
        "hf_logging.set_verbosity_error()\n",
        "\n",
        "\n",
        "class NLIModel(ModelInterface): # Inherit from stub\n",
        "    \"\"\"\n",
        "    Concrete implementation of ModelInterface using Sentence-Transformers and Hugging Face's NLI model.\n",
        "    \"\"\"\n",
        "    def __init__(self, emb_model_name: str, nli_model_name: str, nli_labels: list[str]):\n",
        "        print(\"Initializing heavy models... This happens once.\")\n",
        "        self.emb_model = SentenceTransformer(emb_model_name)\n",
        "        self.nli_tok = AutoTokenizer.from_pretrained(nli_model_name)\n",
        "        self.nli_model = AutoModelForSequenceClassification.from_pretrained(nli_model_name)\n",
        "        self.NLI_LABELS = nli_labels\n",
        "\n",
        "    def get_relatedness_score(self, s1: str, s2: str) -> float:\n",
        "        e1, e2 = self.emb_model.encode([s1, s2], convert_to_tensor=True)\n",
        "        cos = util.cos_sim(e1, e2).item()\n",
        "        return (cos + 1) / 2  # map [-1,1] â†’ [0,1]\n",
        "\n",
        "    def get_nli_probabilities(self, a: str, b: str) -> dict[str, float]:\n",
        "        # Ensure model is on the correct device (e.g., CUDA if available)\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.nli_model.to(device)\n",
        "\n",
        "        x = self.nli_tok.encode_plus(a, b, return_tensors=\"pt\", truncation=True).to(device)\n",
        "        with torch.no_grad():\n",
        "            p = torch.softmax(self.nli_model(**x).logits, dim=-1).squeeze().tolist()\n",
        "        return dict(zip(self.NLI_LABELS, p))\n",
        "\n",
        "    # --- [!] IMPLEMENTED .predict() METHOD ---\n",
        "    def predict(self, inputs: List[Tuple[str, str]]) -> List[Tuple[float, float, float]]:\n",
        "        \"\"\"\n",
        "        Implements the required .predict() method to bridge\n",
        "        the gap with FactValidator.\n",
        "        \"\"\"\n",
        "        results = []\n",
        "        for claim, passage_content in inputs:\n",
        "            prob_dict = self.get_nli_probabilities(claim, passage_content)\n",
        "            e = prob_dict.get(\"entailment\", 0.0)\n",
        "            c = prob_dict.get(\"contradiction\", 0.0)\n",
        "            n = prob_dict.get(\"neutral\", 0.0)\n",
        "            results.append((e, c, n))\n",
        "        return results"
      ],
      "metadata": {
        "id": "e9fv06Gcus1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==============================================================================\n",
        "# --- START OF COMPLETE FactValidator CLASS ---\n",
        "# (Class definition is unchanged)\n",
        "# ==============================================================================\n",
        "\n",
        "class FactValidator:\n",
        "\n",
        "    VERDICT_TO_SCORE_MAP: Dict[VerdictType, int] = {\n",
        "        \"Supported\": 90,\n",
        "        \"Refuted\": 10,\n",
        "        \"Contested\": 50,\n",
        "        \"Not enough evidence\": 25,\n",
        "    }\n",
        "\n",
        "    def __init__(self,\n",
        "                 llm: LLMInterface,\n",
        "                 nli_backend: ModelInterface,\n",
        "                 clf: 'DecisionTreeClassifier' = None,\n",
        "                 encoder: 'LabelEncoder' = None):\n",
        "\n",
        "        self.llm = llm\n",
        "        self.nli = nli_backend\n",
        "        self.related_gate = 0.60 # Relevance threshold\n",
        "        self.agree_cut = 0.60    # Entailment threshold\n",
        "        self.contra_cut = 0.60   # Contradiction threshold\n",
        "        self.clf = clf\n",
        "        self.encoder = encoder\n",
        "\n",
        "    def _prepare_features(self, features: 'FactCheckFeatures', num_agree: int, num_disagree: int, len_valid_results: int, len_passages: int) -> np.ndarray:\n",
        "        feature_vector = [\n",
        "            features.entail_max,\n",
        "            features.entail_mean3,\n",
        "            features.contradict_max,\n",
        "            features.agree_domain_count,\n",
        "            features.releliance_score_avg,\n",
        "            features.recency_weight_max,\n",
        "            features.contest_score,\n",
        "            num_agree,\n",
        "            num_disagree,\n",
        "            len_valid_results,\n",
        "            len_passages\n",
        "        ]\n",
        "        return np.array(feature_vector).reshape(1, -1)\n",
        "\n",
        "    def _calculate_final_score_and_verdict(self, features: 'FactCheckFeatures', num_agree: int, num_disagree: int, len_valid_results: int, len_passages: int) -> Tuple[VerdictType, int]:\n",
        "        \"\"\"\n",
        "        Uses the trained Decision Tree to predict the verdict AND\n",
        "        calculate a confidence score based on the tree's output probabilities.\n",
        "        \"\"\"\n",
        "        if not self.clf or not self.encoder:\n",
        "            raise ValueError(\"Classifier or Encoder not provided. Cannot predict.\")\n",
        "\n",
        "        # 1. Assemble the feature vector in the correct order\n",
        "        X_input = self._prepare_features(\n",
        "            features,\n",
        "            num_agree,\n",
        "            num_disagree,\n",
        "            len_valid_results,\n",
        "            len_passages\n",
        "        )\n",
        "\n",
        "        # 2. Get the probabilities for ALL classes (e.g., [[0.1, 0.05, 0.8, 0.05]])\n",
        "        all_probabilities = self.clf.predict_proba(X_input)\n",
        "\n",
        "        # 3. Get the probabilities for our single input (e.g., [0.1, 0.05, 0.8, 0.05])\n",
        "        class_probabilities = all_probabilities[0]\n",
        "\n",
        "        # 4. Find the highest probability in the list (e.g., 0.8)\n",
        "        #    This is our confidence.\n",
        "        confidence = np.max(class_probabilities)\n",
        "\n",
        "        # 5. Find the INDEX of the highest probability (e.g., 2)\n",
        "        #    This is our predicted numeric label.\n",
        "        predicted_numeric_label = np.argmax(class_probabilities)\n",
        "\n",
        "        # 6. Decode the numeric label back to the string verdict (e.g., \"Refuted\")\n",
        "        verdict: VerdictType = self.encoder.inverse_transform([predicted_numeric_label])[0]\n",
        "\n",
        "        # 7. Convert the confidence (a float from 0.0 to 1.0)\n",
        "        #    to an integer score (from 0 to 100).\n",
        "        score = int(confidence * 100)\n",
        "\n",
        "        return verdict, score\n",
        "\n",
        "    # --- STUBBED METHODS ---\n",
        "\n",
        "    def _get_nli_results(self, claim: str, passage_contents: List[str]) -> List[Tuple[float, float, float]]:\n",
        "        if not self.nli:\n",
        "            raise ValueError(\"NLI backend not provided.\")\n",
        "        inputs = [(claim, content) for content in passage_contents]\n",
        "        return self.nli.predict(inputs)\n",
        "\n",
        "    def _calculate_recency(self, published_at: datetime) -> Tuple[float, bool]:\n",
        "        if not published_at:\n",
        "            return (0.5, False)\n",
        "        days_diff = (datetime.now() - published_at).days\n",
        "        if days_diff < 30:\n",
        "            return (1.0, True)\n",
        "        elif days_diff < 365:\n",
        "            return (0.8, True)\n",
        "        return (0.3, True)\n",
        "\n",
        "    def _calculate_features(self, valid_results: List[ClaimCheckResult]) -> FactCheckFeatures:\n",
        "        if not valid_results:\n",
        "            return FactCheckFeatures(0, 0, 0, 0, 0, 0)\n",
        "\n",
        "        entail_probs = sorted([r.entail_prob for r in valid_results if r.entail_prob > 0.1], reverse=True)\n",
        "        contra_probs = sorted([r.contradict_prob for r in valid_results if r.contradict_prob > 0.1], reverse=True)\n",
        "        domains = {r.passage.domain for r in valid_results if r.entail_prob > self.agree_cut}\n",
        "\n",
        "        entail_max = entail_probs[0] if entail_probs else 0.0\n",
        "        contradict_max = contra_probs[0] if contra_probs else 0.0\n",
        "        return FactCheckFeatures(\n",
        "            entail_max=entail_max,\n",
        "            entail_mean3=np.mean(entail_probs[:3]) if entail_probs else 0.0,\n",
        "            contradict_max=contradict_max,\n",
        "            agree_domain_count=len(domains),\n",
        "            releliance_score_avg=np.mean([r.passage.relevance_score for r in valid_results]),\n",
        "            recency_weight_max=max(r.recency_weight for r in valid_results),\n",
        "            contest_score = entail_max * contradict_max\n",
        "        )\n",
        "\n",
        "    def _get_top_citations(self, valid_results: List[ClaimCheckResult], num_agree: int, num_disagree: int) -> List[Citation]:\n",
        "        sorted_results = sorted(valid_results, key=lambda r: r.passage.relevance_score, reverse=True)\n",
        "        return [Citation(passage=r.passage) for r in sorted_results[:3]]\n",
        "\n",
        "    # --- MAIN VALIDATION & GENERATION LOGIC ---\n",
        "\n",
        "    def validate_claim(self, claim: str, passages: List[SourcePassage]) -> FactCheckResult:\n",
        "        # 1. Filter by relevance\n",
        "        related_passages = [p for p in passages if p.relevance_score >= self.related_gate]\n",
        "        len_passages = len(related_passages)\n",
        "\n",
        "        if not related_passages:\n",
        "            features = FactCheckFeatures(0, 0, 0, 0, 0, 0)\n",
        "            return FactCheckResult(claim, \"Not enough evidence\", -1, [], features)\n",
        "\n",
        "        # 2. Get NLI results\n",
        "        passage_contents = [p.content for p in related_passages]\n",
        "        nli_results = self._get_nli_results(claim, passage_contents)\n",
        "\n",
        "        # 3. Combine all info\n",
        "        all_results = []\n",
        "        for passage, (e, c, n) in zip(related_passages, nli_results):\n",
        "            recency_w, date_ok = self._calculate_recency(passage.published_at)\n",
        "            all_results.append(ClaimCheckResult(\n",
        "                passage=passage, entail_prob=e, contradict_prob=c, neutral_prob=n,\n",
        "                recency_weight=recency_w, numeric_date_ok=date_ok\n",
        "            ))\n",
        "\n",
        "        # 4. Filter valid results (not strongly neutral)\n",
        "        valid_results = [r for r in all_results if r.entail_prob > 0.5 or r.contradict_prob > 0.5]\n",
        "        len_valid_results = len(valid_results)\n",
        "\n",
        "        if not valid_results:\n",
        "            features = FactCheckFeatures(0, 0, 0, 0, 0, 0)\n",
        "            return FactCheckResult(claim, \"Not enough evidence\", -1, [], features)\n",
        "\n",
        "        # 5. Get counts\n",
        "        num_agree = sum(1 for r in valid_results if r.entail_prob > self.agree_cut)\n",
        "        num_disagree = sum(1 for r in valid_results if r.contradict_prob > self.contra_cut)\n",
        "\n",
        "        # 6. Calculate features\n",
        "        features = self._calculate_features(valid_results)\n",
        "\n",
        "        # 7. Get final verdict (using the decision tree)\n",
        "        verdict, score = self._calculate_final_score_and_verdict(\n",
        "            features, num_agree, num_disagree, len_valid_results, len_passages\n",
        "        )\n",
        "\n",
        "        # 8. Get citations\n",
        "        citations = self._get_top_citations(valid_results, num_agree, num_disagree)\n",
        "\n",
        "        return FactCheckResult(claim, verdict, score, citations, features)\n",
        "\n",
        "    def generate_training_example(self, claim: str, passages: List[SourcePassage]) -> Tuple[FactCheckFeatures, int, int, int, int]:\n",
        "        # 1. Filter by relevance\n",
        "        related_passages = [p for p in passages if p.relevance_score >= self.related_gate]\n",
        "        len_passages = len(related_passages)\n",
        "\n",
        "        if not related_passages:\n",
        "            features = FactCheckFeatures(0, 0, 0, 0, 0, 0)\n",
        "            return features, 0, 0, 0, 0\n",
        "\n",
        "        # 2. Get NLI results\n",
        "        passage_contents = [p.content for p in related_passages]\n",
        "        nli_results = self._get_nli_results(claim, passage_contents)\n",
        "\n",
        "        # 3. Combine all info\n",
        "        all_results = []\n",
        "        for passage, (e, c, n) in zip(related_passages, nli_results):\n",
        "            recency_w, date_ok = self._calculate_recency(passage.published_at)\n",
        "            all_results.append(ClaimCheckResult(\n",
        "                passage=passage, entail_prob=e, contradict_prob=c, neutral_prob=n,\n",
        "                recency_weight=recency_w, numeric_date_ok=date_ok\n",
        "            ))\n",
        "\n",
        "        # 4. Filter valid results\n",
        "        valid_results = [r for r in all_results if r.entail_prob > 0.3 or r.contradict_prob > 0.3]\n",
        "        len_valid_results = len(valid_results)\n",
        "\n",
        "        if not valid_results:\n",
        "            features = FactCheckFeatures(0, 0, 0, 0, 0, 0)\n",
        "            return features, 0, 0, 0, len_passages # Return len_passages\n",
        "\n",
        "        # 5. Get counts\n",
        "        num_agree = sum(1 for r in valid_results if r.entail_prob > self.agree_cut)\n",
        "        num_disagree = sum(1 for r in valid_results if r.contradict_prob > self.contra_cut)\n",
        "\n",
        "        # 6. Calculate features\n",
        "        features = self._calculate_features(valid_results)\n",
        "\n",
        "        # 7. Return the raw features and counts\n",
        "        return features, num_agree, num_disagree, len_valid_results, len_passages\n",
        "\n"
      ],
      "metadata": {
        "id": "D6zzaH2Xuv-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# --- START OF \"TRAINING\" SCRIPT ---\n",
        "# ==============================================================================\n",
        "\n",
        "# --- Step 1: Define Your \"Gold Standard\" Raw Dataset ---\n",
        "@dataclass\n",
        "class GoldStandardExample:\n",
        "    claim: str\n",
        "    passages: List[SourcePassage]\n",
        "    ground_truth_verdict: VerdictType\n",
        "\n",
        "NOW = datetime.now()\n",
        "RECENT = NOW - timedelta(days=10)\n",
        "OLD = NOW - timedelta(days=700)\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, Any, List, Tuple, Set, Literal\n",
        "\n",
        "# --- Define required dataclasses and types (for a runnable block) ---\n",
        "VerdictType = Literal[\"Supported\", \"Refuted\", \"Not enough evidence\", \"Contested\"]\n",
        "class SourcePassage:\n",
        "    def __init__(self, content, domain, relevance_score, published_at):\n",
        "        self.content = content\n",
        "        self.domain = domain\n",
        "        self.relevance_score = relevance_score\n",
        "        self.published_at = published_at\n",
        "@dataclass\n",
        "class GoldStandardExample:\n",
        "    claim: str\n",
        "    passages: List[SourcePassage]\n",
        "    ground_truth_verdict: VerdictType\n",
        "\n",
        "# --- Define date constants ---\n",
        "NOW = datetime.now()\n",
        "RECENT = NOW - timedelta(days=10)\n",
        "OLD = NOW - timedelta(days=700)\n",
        "VERY_OLD = NOW - timedelta(days=2000)"
      ],
      "metadata": {
        "id": "a9yTL0jGvIYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsykFD4Mhugq",
        "outputId": "4f26f31e-25e3-4fa1-aedd-049ca886b345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated a new dataset with 101 examples.\n"
          ]
        }
      ],
      "source": [
        "# --- Define date constants ---\n",
        "NOW = datetime.now()\n",
        "RECENT = NOW - timedelta(days=10)\n",
        "OLD = NOW - timedelta(days=700)\n",
        "VERY_OLD = NOW - timedelta(days=2000)\n",
        "\n",
        "# ==============================================================================\n",
        "# --- 100 NEW GOLD STANDARD EXAMPLES ---\n",
        "# ==============================================================================\n",
        "\n",
        "gold_standard_dataset = [\n",
        "    # --- NEW \"SUPPORTED\" (25) ---\n",
        "    GoldStandardExample(\n",
        "        claim=\"The Earth revolves around the Sun.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The heliocentric model, which states that the Earth orbits the Sun, is the accepted astronomical model.\",\n",
        "                          domain=\"nasa.gov\", relevance_score=0.99, published_at=RECENT),\n",
        "            SourcePassage(content=\"Our planet, Earth, travels in an orbit around the Sun, taking approximately 365.25 days to complete one revolution.\",\n",
        "                          domain=\"astronomy.com\", relevance_score=0.95, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Bill Gates co-founded Microsoft.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Microsoft was founded by Bill Gates and Paul Allen on April 4, 1975.\",\n",
        "                          domain=\"forbes.com\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The Amazon is the longest river in the world.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Recent studies measuring the Amazon River from its source in Peru confirm it is the world's longest river, surpassing the Nile.\",\n",
        "                          domain=\"natgeo.com\", relevance_score=0.95, published_at=RECENT),\n",
        "            SourcePassage(content=\"The Amazon River in South America is widely recognized as the longest river, just edging out the Nile.\",\n",
        "                          domain=\"geography.com\", relevance_score=0.9, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Helium is a noble gas.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Helium (He) is a chemical element, a colorless, odorless, tasteless, non-toxic, inert, monatomic gas, the first in the noble gas group in the periodic table.\",\n",
        "                          domain=\"chemistry.org\", relevance_score=0.99, published_at=VERY_OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"World War II ended in 1945.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The war in Europe concluded with Germany's surrender in May 1945, and the war in the Pacific ended with Japan's surrender in September 1945.\",\n",
        "                          domain=\"history.com\", relevance_score=0.98, published_at=RECENT),\n",
        "            SourcePassage(content=\"Hostilities of World War II formally ceased in the autumn of 1945.\",\n",
        "                          domain=\"britannica.com\", relevance_score=0.95, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Mount Everest is the tallest mountain above sea level.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Mount Everest, located in the Himalayas, is Earth's highest mountain above sea level, with its peak at 8,848.86 metres.\",\n",
        "                          domain=\"wiki.org\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Penguins are flightless birds.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Penguins (order Sphenisciformes) are a group of aquatic flightless birds.\",\n",
        "                          domain=\"audubon.org\", relevance_score=0.99, published_at=RECENT),\n",
        "            SourcePassage(content=\"While they cannot fly through the air, their wings have evolved into flippers, making them excellent swimmers.\",\n",
        "                          domain=\"wildlife.com\", relevance_score=0.9, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The capital of Japan is Tokyo.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Tokyo, formerly known as Edo, is the capital and most populous metropolis of Japan.\",\n",
        "                          domain=\"japan-guide.com\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Mars is the fourth planet from the Sun.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"In our solar system, Mars is the fourth planet from the Sun, orbiting after Earth.\",\n",
        "                          domain=\"nasa.gov\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The primary language spoken in Brazil is Portuguese.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Due to its history as a Portuguese colony, the official and most widely spoken language in Brazil is Portuguese.\",\n",
        "                          domain=\"brazil.gov.br\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Sharks are a type of fish.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Sharks are classified as fish. Specifically, they are elasmobranchs, meaning they have skeletons made of cartilage.\",\n",
        "                          domain=\"marinebio.org\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The currency of the United Kingdom is the Pound Sterling.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The United Kingdom uses the Pound Sterling (Â£), often just called the pound, as its official currency.\",\n",
        "                          domain=\"bankofengland.co.uk\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The human heart has four chambers.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The human heart is a four-chambered organ, consisting of the right and left atria, and the right and left ventricles.\",\n",
        "                          domain=\"heart.org\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The acronym 'LASER' stands for Light Amplification by Stimulated Emission of Radiation.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"LASER is an acronym for Light Amplification by Stimulated Emission of Radiation.\",\n",
        "                          domain=\"physics.org\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Neil Armstrong was the first person to walk on the Moon.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"On July 20, 1969, American astronaut Neil Armstrong became the first human to step onto the lunar surface.\",\n",
        "                          domain=\"nasa.gov\", relevance_score=0.99, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"William Shakespeare wrote 'Hamlet'.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"'Hamlet' is a tragedy written by William Shakespeare sometime between 1599 and 1601.\",\n",
        "                          domain=\"shakespeare.org\", relevance_score=0.99, published_at=VERY_OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The atomic number of Carbon is 6.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Carbon is a chemical element with symbol C and atomic number 6.\",\n",
        "                          domain=\"rsc.org\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The Statue of Liberty was a gift to the US from France.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The Statue of Liberty was a gift of friendship from the people of France to the United States and was dedicated on October 28, 1886.\",\n",
        "                          domain=\"nps.gov\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Spiders are arachnids, not insects.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Spiders belong to the class Arachnida, which also includes scorpions, mites, and ticks. They are not insects, which belong to the class Insecta.\",\n",
        "                          domain=\"biology.edu\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Mount Kilimanjaro is in Tanzania.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Mount Kilimanjaro, Africa's highest peak, is located in northeastern Tanzania.\",\n",
        "                          domain=\"tanzaniatourism.go.tz\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Photosynthesis is the process plants use to make food.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Photosynthesis is the process by which green plants use sunlight, water, and carbon dioxide to create their own food and release oxygen.\",\n",
        "                          domain=\"nature.com\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The speed of light is approximately 300,000 km/s in a vacuum.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The speed of light in a vacuum is a universal constant, precisely 299,792,458 metres per second (about 300,000 km/s).\",\n",
        "                          domain=\"physics.nist.gov\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The Nile River flows north.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The Nile River is one of the few major rivers that flows from south to north, emptying into the Mediterranean Sea.\",\n",
        "                          domain=\"geography.com\", relevance_score=0.98, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Isaac Newton formulated the laws of motion.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Sir Isaac Newton's laws of motion, which are the basis of classical mechanics, were first published in his work 'PhilosophiÃ¦ Naturalis Principia Mathematica' in 1687.\",\n",
        "                          domain=\"history.com\", relevance_score=0.99, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The Pacific Ocean is the world's largest ocean.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Covering more than 63 million square miles, the Pacific Ocean is the largest and deepest of Earth's five oceans.\",\n",
        "                          domain=\"noaa.gov\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Supported\"\n",
        "    ),\n",
        "\n",
        "    # --- NEW \"REFUTED\" (25) ---\n",
        "    GoldStandardExample(\n",
        "        claim=\"Bats are blind.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"It is a common myth that bats are blind. All bat species have eyes and can see. Many also use echolocation.\",\n",
        "                          domain=\"wildlife.org\", relevance_score=0.99, published_at=RECENT),\n",
        "            SourcePassage(content=\"Contrary to popular belief, bats are not blind. Fruit bats, for example, have excellent night vision.\",\n",
        "                          domain=\"science.com\", relevance_score=0.95, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The capital of the United States is New York City.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The capital of the United States is Washington, D.C. New York City is its largest city, but not the capital.\",\n",
        "                          domain=\"gov.us\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Humans can photosynthesize.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Humans, like all animals, are heterotrophs and cannot perform photosynthesis. We must consume food for energy. Only plants, algae, and some bacteria can photosynthesize.\",\n",
        "                          domain=\"biology.edu\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The Titanic sank in 1920.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The RMS Titanic sank in the early morning hours of April 15, 1912, not 1920.\",\n",
        "                          domain=\"history.com\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Penguins live in the Arctic.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Penguins live almost exclusively in the Southern Hemisphere. No penguin species are native to the Arctic.\",\n",
        "                          domain=\"antarctica.gov\", relevance_score=0.99, published_at=RECENT),\n",
        "            SourcePassage(content=\"Polar bears live in the Arctic, while penguins live in the Antarctic. They do not live in the same polar region.\",\n",
        "                          domain=\"worldwildlife.org\", relevance_score=0.95, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Christopher Columbus discovered America.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Christopher Columbus did not 'discover' America. The continent was already inhabited by millions of indigenous people for millennia.\",\n",
        "                          domain=\"history.org\", relevance_score=0.98, published_at=RECENT),\n",
        "            SourcePassage(content=\"Vikings, such as Leif Erikson, are believed to have reached North America around 1000 AD, nearly 500 years before Columbus.\",\n",
        "                          domain=\"smithsonian.com\", relevance_score=0.9, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Mars is the largest planet in our solar system.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The largest planet in our solar system is Jupiter. Mars is the second-smallest, larger only than Mercury.\",\n",
        "                          domain=\"nasa.gov\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Diamonds are made from compressed coal.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"This is a common misconception. Diamonds are formed from carbon deep within the Earth's mantle under high pressure and temperature, but they are not made from coal.\",\n",
        "                          domain=\"gia.edu\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Venus is the coldest planet.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Venus is the hottest planet in our solar system, with an average surface temperature of 465Â°C (869Â°F), due to its thick atmosphere.\",\n",
        "                          domain=\"space.com\", relevance_score=0.99, published_at=RECENT),\n",
        "            SourcePassage(content=\"The coldest planet is Neptune, with temperatures dropping to -224Â°C (-371Â°F).\",\n",
        "                          domain=\"nasa.gov\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Humans have only five senses.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The traditional five senses (sight, smell, hearing, taste, touch) are a misnomer. Humans also have senses like proprioception (body position) and nociception (pain).\",\n",
        "                          domain=\"neuroscience.com\", relevance_score=0.98, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The Great Wall of China is the only man-made object visible from space.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The idea that the Great Wall of China is visible from space with the naked eye is a persistent myth. It is not.\",\n",
        "                          domain=\"nasa.gov\", relevance_score=0.99, published_at=RECENT),\n",
        "            SourcePassage(content=\"No single man-made object is clearly visible from orbit. Astronauts can see cities, roads, and dams, but not the Great Wall.\",\n",
        "                          domain=\"scientificamerican.com\", relevance_score=0.9, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Whales are large fish.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Whales are not fish; they are marine mammals. They are warm-blooded, breathe air, and give birth to live young.\",\n",
        "                          domain=\"noaa.gov\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Albert Einstein failed mathematics in school.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"This is a popular myth. Albert Einstein excelled in mathematics and physics from a young age. He mastered differential and integral calculus by age 15.\",\n",
        "                          domain=\"history.com\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The primary language of Switzerland is Swiss.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"There is no single language called 'Swiss'. Switzerland has four national languages: German, French, Italian, and Romansh.\",\n",
        "                          domain=\"admin.ch\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"All deserts are hot.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"This is false. A desert is defined by its low precipitation, not its temperature. Antarctica is the world's largest desert, and it is extremely cold.\",\n",
        "                          domain=\"usgs.gov\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Tomatoes are vegetables.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Botanically speaking, a tomato is a fruit because it develops from the flower's ovary and contains seeds.\",\n",
        "                          domain=\"botany.org\", relevance_score=0.98, published_at=RECENT),\n",
        "            SourcePassage(content=\"While legally classified as a vegetable for trade purposes in the US, in a scientific context, tomatoes are fruits.\",\n",
        "                          domain=\"science.edu\", relevance_score=0.9, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The original name of Twitter was 'FriendStalker'.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"This is a myth. The project's original code name was 'twttr'. It was never named 'FriendStalker'.\",\n",
        "                          domain=\"techcrunch.com\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Water flows clockwise down drains in the Northern Hemisphere.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The Coriolis effect is too weak to influence the direction of water in a small basin like a drain. The spin is determined by the shape of the drain and the initial water movement, not the hemisphere.\",\n",
        "                          domain=\"physics.com\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The circumference of the Earth is 10,000 km.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The Earth's equatorial circumference is approximately 40,075 kilometers (24,901 miles).\",\n",
        "                          domain=\"geography.com\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Chameleons change color to match their surroundings.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Chameleons primarily change color to regulate their body temperature and to communicate with other chameleons, not to camouflage with their surroundings.\",\n",
        "                          domain=\"natgeo.com\", relevance_score=0.98, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The speed of sound is faster than the speed of light.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The speed of light (about 300,000 km/s) is vastly faster than the speed of sound (about 0.343 km/s in air).\",\n",
        "                          domain=\"physics.org\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The currency of Canada is the US Dollar.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The official currency of Canada is the Canadian Dollar (CAD), not the US Dollar (USD).\",\n",
        "                          domain=\"bankofcanada.ca\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Vikings wore horned helmets.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"There is no historical evidence that Vikings wore horned helmets in battle. This was an invention of 19th-century opera costumes.\",\n",
        "                          domain=\"history.com\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Mount Rushmore was a natural formation.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Mount Rushmore is a massive sculpture carved into the side of a mountain by Gutzon Borglum and his team. It is not a natural formation.\",\n",
        "                          domain=\"nps.gov\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Jupiter is a star.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Jupiter is the largest planet in our solar system. It is a gas giant, but it is not massive enough to ignite nuclear fusion and become a star.\",\n",
        "                          domain=\"nasa.gov\", relevance_score=0.99, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Refuted\"\n",
        "    ),\n",
        "\n",
        "    # --- NEW \"CONTESTED\" (25) ---\n",
        "    GoldStandardExample(\n",
        "        claim=\"A hot dog is a sandwich.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Based on the 'filling between bread' definition, a hot dog qualifies as a sandwich.\",\n",
        "                          domain=\"foodtheory.com\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"The National Hot Dog Council states that a hot dog is not a sandwich; it is in a category of its own.\",\n",
        "                          domain=\"hotdog.org\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Social media is bad for mental health.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Studies link high social media use to increased rates of anxiety and depression, especially in teens.\",\n",
        "                          domain=\"psychology.org\", relevance_score=0.95, published_at=RECENT),\n",
        "            SourcePassage(content=\"Conversely, social media can foster community and reduce loneliness for isolated individuals.\",\n",
        "                          domain=\"wellness.com\", relevance_score=0.9, published_at=OLD),\n",
        "            SourcePassage(content=\"The effect of social media is complex; it is not inherently good or bad, but depends on usage patterns.\",\n",
        "                          domain=\"research.com\", relevance_score=0.85, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Nuclear power is a safe energy source.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Modern nuclear power plants are incredibly safe, with multiple redundant safety systems. Statistically, it is one of the safest forms of energy.\",\n",
        "                          domain=\"energy.gov\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"Accidents like Chernobyl and Fukushima highlight the catastrophic and long-term risks associated with nuclear power, making it inherently unsafe.\",\n",
        "                          domain=\"greenpeace.org\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Working from home increases productivity.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"A Stanford study found that remote workers were 13% more productive than their in-office counterparts.\",\n",
        "                          domain=\"stanford.edu\", relevance_score=0.9, published_at=OLD),\n",
        "            SourcePassage(content=\"Many managers report a decrease in collaboration and innovation, arguing that true productivity has fallen since the shift to remote work.\",\n",
        "                          domain=\"hbr.org\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Bitcoin is a good long-term investment.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Proponents argue that Bitcoin's scarcity and decentralized nature make it a 'digital gold' and a strong hedge against inflation.\",\n",
        "                          domain=\"coindesk.com\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"Critics point to its extreme volatility, lack of intrinsic value, and regulatory risks, calling it a purely speculative bubble.\",\n",
        "                          domain=\"ft.com\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Genetically modified (GMO) foods are safe to eat.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The World Health Organization (WHO) states that GMO foods currently on the market have passed safety assessments and are not likely to present risks to human health.\",\n",
        "                          domain=\"who.int\", relevance_score=0.95, published_at=RECENT),\n",
        "            SourcePassage(content=\"Some studies suggest potential long-term risks and allergic reactions, and critics demand more independent, long-term research.\",\n",
        "                          domain=\"nongmoproject.org\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Pineapple belongs on pizza.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The sweetness of pineapple provides a necessary contrast to the salty and savory flavors of ham and cheese, creating a balanced and delicious pizza.\",\n",
        "                          domain=\"foodies.com\", relevance_score=0.85, published_at=RECENT),\n",
        "            SourcePassage(content=\"Italian culinary tradition strictly forbids fruit on pizza. Pineapple is an abomination that ruins the dish's integrity.\",\n",
        "                          domain=\"italyfood.it\", relevance_score=0.88, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim='The \"five-second rule\" is real.',\n",
        "        passages=[\n",
        "            SourcePassage(content=\"A recent study showed that some bacteria can transfer to food in less than one second, disproving the 'five-second rule'.\",\n",
        "                          domain=\"science.com\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"While bacteria transfer is instant, some tests show that the duration of contact does matter, with fewer germs transferring in the first few seconds.\",\n",
        "                          domain=\"mythbusters.com\", relevance_score=0.85, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Electric cars are better for the environment than gas cars.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Electric cars produce zero tailpipe emissions, significantly reducing urban air pollution.\",\n",
        "                          domain=\"epa.gov\", relevance_score=0.95, published_at=RECENT),\n",
        "            SourcePassage(content=\"The environmental impact of manufacturing the batteries and the source of the electricity (e.g., coal) means EVs are not always cleaner.\",\n",
        "                          domain=\"research.com\", relevance_score=0.92, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Shakespeare's plays were written by someone else.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Mainstream scholars overwhelmingly agree that William Shakespeare of Stratford-upon-Avon wrote the plays attributed to him.\",\n",
        "                          domain=\"shakespeare.org\", relevance_score=0.9, published_at=OLD),\n",
        "            SourcePassage(content=\"The 'Oxfordian' theory proposes that Edward de Vere, the 17th Earl of Oxford, was the true author of the plays, citing his education and court knowledge.\",\n",
        "                          domain=\"doubt.org\", relevance_score=0.85, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"A college degree is necessary for a successful career.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"College graduates, on average, earn significantly more over their lifetime than those with only a high school diploma.\",\n",
        "                          domain=\"bls.gov\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"Many successful entrepreneurs and tech leaders, such as Steve Jobs and Mark Zuckerberg, were college dropouts. Skilled trades also offer high-paying careers without a degree.\",\n",
        "                          domain=\"forbes.com\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Breakfast is the most important meal of the day.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Eating a nutritious breakfast is associated with better concentration and metabolic health.\",\n",
        "                          domain=\"health.com\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"Recent studies on intermittent fasting challenge this idea, suggesting that *when* you eat may be less important than *what* you eat.\",\n",
        "                          domain=\"nejm.org\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The sinking of the Lusitania caused the US to enter WWI.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The sinking of the Lusitania in 1915, which killed 128 Americans, greatly turned public opinion against Germany and was a major factor in the US entry.\",\n",
        "                          domain=\"history.com\", relevance_score=0.9, published_at=OLD),\n",
        "            SourcePassage(content=\"The US did not enter WWI until 1917, two years after the Lusitania. The Zimmermann Telegram was the more direct and final cause for war.\",\n",
        "                          domain=\"academic.org\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Nikola Tesla was a better inventor than Thomas Edison.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Tesla's work on AC power systems was revolutionary and forms the basis of our modern electrical grid, proving his superior genius.\",\n",
        "                          domain=\"tesla-bio.com\", relevance_score=0.85, published_at=RECENT),\n",
        "            SourcePassage(content=\"Edison's practical inventions, like the phonograph and the first commercially viable light bulb, and his business acumen had a more immediate and widespread impact on society.\",\n",
        "                          domain=\"edison.com\", relevance_score=0.85, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Astrology accurately predicts personality traits.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Astrology is a pseudoscience. Scientific studies have repeatedly found no evidence that astronomical phenomena can predict personality or life events.\",\n",
        "                          domain=\"nature.com\", relevance_score=0.95, published_at=RECENT),\n",
        "            SourcePassage(content=\"Millions of people read their horoscopes daily and feel that their zodiac sign accurately describes their personality.\",\n",
        "                          domain=\"astrology.com\", relevance_score=0.8, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The universal basic income (UBI) is a viable economic policy.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Experiments with UBI have shown it can reduce poverty and improve health outcomes without reducing the will to work.\",\n",
        "                          domain=\"ubi-studies.org\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"Economists warn that a UBI would be prohibitively expensive, requiring massive tax hikes and potentially causing runaway inflation.\",\n",
        "                          domain=\"econ.com\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim='The \"Mediterranean Diet\" is the healthiest diet.',\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Numerous studies have linked the Mediterranean diet to a lower risk of heart disease, stroke, and premature death.\",\n",
        "                          domain=\"heart.org\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"While healthy, critics note that other diets, like the DASH diet or a traditional Okinawan diet, show similarly strong health benefits.\",\n",
        "                          domain=\"nutrition.com\", relevance_score=0.85, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Video games cause violent behavior.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The American Psychological Association (APA) has stated there is insufficient scientific evidence to link violent video games to criminal violence.\",\n",
        "                          domain=\"apa.org\", relevance_score=0.95, published_at=RECENT),\n",
        "            SourcePassage(content=\"Some studies have shown a short-term increase in aggressive thoughts and behavior after playing violent video games.\",\n",
        "                          domain=\"psychology-studies.com\", relevance_score=0.85, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Self-driving cars will be common by 2030.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Major auto and tech companies are pouring billions into autonomous driving, with many CEOs promising fully self-driving cars on the market by 2030.\",\n",
        "                          domain=\"tech.com\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"The technical and regulatory hurdles, especially 'edge cases' in driving, are far more complex than anticipated, making a 2030 deadline for widespread adoption highly unlikely.\",\n",
        "                          domain=\"robotics.org\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Organic food is more nutritious than conventional food.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"A large-scale analysis in the British Journal of Nutrition found that organic produce has significantly higher concentrations of antioxidants.\",\n",
        "                          domain=\"cambridge.org\", relevance_score=0.9, published_at=OLD),\n",
        "            SourcePassage(content=\"A Stanford University meta-analysis found no strong evidence that organic foods are significantly more nutritious than conventional foods.\",\n",
        "                          domain=\"stanford.edu\", relevance_score=0.9, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Julius Caesar was the first Emperor of Rome.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Julius Caesar was a 'dictator perpetuo' (dictator for life), but he was assassinated before he could become emperor. His adopted son, Augustus, became the first true Roman Emperor in 27 BC.\",\n",
        "                          domain=\"history.com\", relevance_score=0.95, published_at=RECENT),\n",
        "            SourcePassage(content=\"Many popular histories refer to Julius Caesar as the first emperor due to his consolidation of power and the end of the Roman Republic.\",\n",
        "                          domain=\"biography.com\", relevance_score=0.8, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The 10,000-hour rule is the key to success.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Malcolm Gladwell's '10,000-hour rule' posits that mastery in any field requires that amount of deliberate practice.\",\n",
        "                          domain=\"books.com\", relevance_score=0.85, published_at=OLD),\n",
        "            SourcePassage(content=\"The original researcher, Anders Ericsson, stated that the rule is an oversimplification and that other factors, like natural talent and quality of practice, are equally important.\",\n",
        "                          domain=\"psychology.com\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Dogs are smarter than cats.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Studies show that dogs have more neurons in their cerebral cortex than cats, which is a strong indicator of higher cognitive ability.\",\n",
        "                          domain=\"neuroscience.com\", relevance_score=0.85, published_at=RECENT),\n",
        "            SourcePassage(content=\"Comparing dog and cat intelligence is difficult as their skills are different. Cats are highly independent problem-solvers, excelling in different areas than social dogs.\",\n",
        "                          domain=\"animal-behavior.com\", relevance_score=0.85, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim='The \"Big Bang\" was an explosion.',\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The Big Bang was not an explosion in space. It was the rapid expansion of space itself from an initial point of high density.\",\n",
        "                          domain=\"nasa.gov\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"The term 'Big Bang' is a popular and evocative term used to describe the explosive origin of the universe.\",\n",
        "                          domain=\"popular-science.com\", relevance_score=0.8, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Free will is an illusion.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Some neuroscientists argue that brain activity precedes conscious decisions, suggesting our feeling of 'choice' is an illusion created after the fact.\",\n",
        "                          domain=\"neuro.org\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"Philosophers in the compatibilist camp argue that free will is compatible with determinism, and that our ability to reason and make choices is a meaningful form of freedom.\",\n",
        "                          domain=\"philosophy.edu\", relevance_score=0.9, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Contested\"\n",
        "    ),\n",
        "\n",
        "    # --- NEW \"NOT ENOUGH EVIDENCE\" (25) ---\n",
        "    GoldStandardExample(\n",
        "        claim=\"Leonardo da Vinci was a nice person.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Leonardo da Vinci was an Italian polymath, painter, sculptor, and architect.\",\n",
        "                          domain=\"history.com\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"His most famous painting is the Mona Lisa, which is in the Louvre.\",\n",
        "                          domain=\"art.edu\", relevance_score=0.9, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The best color to paint a living room is blue.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Blue is a color often associated with calm and serenity.\",\n",
        "                          domain=\"design.com\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"Paint sales have increased in the spring.\",\n",
        "                          domain=\"retail.com\", relevance_score=0.7, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Life exists on Mars.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"NASA's Perseverance rover is currently searching for signs of ancient microbial life in Jezero Crater.\",\n",
        "                          domain=\"nasa.gov\", relevance_score=0.95, published_at=RECENT),\n",
        "            SourcePassage(content=\"Mars has a thin atmosphere composed mostly of carbon dioxide.\",\n",
        "                          domain=\"space.com\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The new Tesla Roadster will be released in 2025.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The Tesla Roadster was first announced in 2017.\",\n",
        "                          domain=\"tesla.com\", relevance_score=0.9, published_at=OLD),\n",
        "            SourcePassage(content=\"Elon Musk has repeatedly delayed the Roadster's production, and no firm release date has been set.\",\n",
        "                          domain=\"car-news.com\", relevance_score=0.95, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"A specific person, 'John Smith', is 40 years old.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"John Smith is a very common name in the United States.\",\n",
        "                          domain=\"census.gov\", relevance_score=0.8, published_at=RECENT),\n",
        "            SourcePassage(content=\"There is a 'John Smith' listed as CEO of a tech company.\",\n",
        "                          domain=\"tech.com\", relevance_score=0.7, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The stock market will go up tomorrow.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The stock market closed at a record high today.\",\n",
        "                          domain=\"wsj.com\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"Stock market movements are notoriously difficult to predict in the short term.\",\n",
        "                          domain=\"investopedia.com\", relevance_score=0.8, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Ghosts are real.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Many people report seeing apparitions or experiencing unexplained phenomena.\",\n",
        "                          domain=\"paranormal.com\", relevance_score=0.8, published_at=RECENT),\n",
        "            SourcePassage(content=\"Science has found no empirical evidence for the existence of ghosts or spirits.\",\n",
        "                          domain=\"science.org\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The lost city of Atlantis has been found.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The story of Atlantis originates from Plato's dialogues.\",\n",
        "                          domain=\"history.com\", relevance_score=0.9, published_at=OLD),\n",
        "            SourcePassage(content=\"Numerous expeditions have searched for Atlantis, but no definitive discovery has been confirmed by the mainstream scientific community.\",\n",
        "                          domain=\"archaeology.com\", relevance_score=0.95, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"This specific apple is delicious.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"This apple is a 'Honeycrisp' apple, a popular variety.\",\n",
        "                          domain=\"grocery.com\", relevance_score=0.8, published_at=RECENT),\n",
        "            SourcePassage(content=\"The apple is red and appears to be ripe.\",\n",
        "                          domain=\"farming.com\", relevance_score=0.7, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The Earth's core has stopped spinning.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The Earth's core is composed of a solid inner core and a liquid outer core.\",\n",
        "                          domain=\"usgs.gov\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"Recent studies suggest the inner core's rotation may have paused or slightly reversed relative to the mantle, but it has not 'stopped' completely.\",\n",
        "                          domain=\"nature.com\", relevance_score=0.95, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Bigfoot has been captured.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Bigfoot, or Sasquatch, is a mythical creature in North American folklore.\",\n",
        "                          domain=\"folklore.com\", relevance_score=0.8, published_at=RECENT),\n",
        "            SourcePassage(content=\"No body or definitive proof of Bigfoot has ever been found or captured.\",\n",
        "                          domain=\"fbi.gov\", relevance_score=0.9, published_at=OLD),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The politician Jane Doe is honest.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Jane Doe voted 'Yes' on the recent infrastructure bill.\",\n",
        "                          domain=\"congress.gov\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"A watchdog group gave Jane Doe a 'C' rating on transparency.\",\n",
        "                          domain=\"watchdog.org\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"A new laptop model 'X' is the best for students.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The new laptop model 'X' was released last week.\",\n",
        "                          domain=\"tech.com\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"It features a 13-inch screen and a new M4 processor.\",\n",
        "                          domain=\"specs.com\", relevance_score=0.8, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The cure for baldness will be available next year.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Scientists are researching new treatments for hair loss, including gene therapy.\",\n",
        "                          domain=\"research.com\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"No treatment has completed Phase III clinical trials and been approved as a 'cure'.\",\n",
        "                          domain=\"fda.gov\", relevance_score=0.95, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Dogs are happier than cats.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Dogs are highly social pack animals that often display overt signs of affection.\",\n",
        "                          domain=\"pets.com\", relevance_score=0.8, published_at=RECENT),\n",
        "            SourcePassage(content=\"Cats are more solitary animals, and their signs of happiness, like purring, are more subtle.\",\n",
        "                          domain=\"vet.com\", relevance_score=0.8, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The pyramids were built by aliens.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The Great Pyramid of Giza is a marvel of ancient engineering, built around 2580 BC.\",\n",
        "                          domain=\"history.com\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"Archaeologists have found extensive evidence of the ramps, tools, and labor force used to build the pyramids.\",\n",
        "                          domain=\"archaeology.org\", relevance_score=0.95, published_at=RECENT),\n",
        "            SourcePassage(content=\"There is no scientific or historical evidence to support the theory of extraterrestrial involvement.\",\n",
        "                          domain=\"science.com\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"It will rain in London next Tuesday.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"London is known for its frequently rainy and overcast weather.\",\n",
        "                          domain=\"weather.com\", relevance_score=0.8, published_at=RECENT),\n",
        "            SourcePassage(content=\"Long-range weather forecasts are highly unreliable and subject to change.\",\n",
        "                          domain=\"metoffice.gov.uk\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The next president of the US will be from Texas.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The next US presidential election is scheduled for November 2028.\",\n",
        "                          domain=\"gov.us\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"Several potential candidates have been mentioned in the news, but no one has officially secured the nomination.\",\n",
        "                          domain=\"news.com\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The average house price in the US will fall in 2026.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Current interest rates are high, which has slowed the housing market.\",\n",
        "                          domain=\"realtor.com\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"Economic forecasting two years out is highly speculative and depends on many factors.\",\n",
        "                          domain=\"econ.com\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The new movie 'Space Wars 5' is good.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"'Space Wars 5' was released in theaters today.\",\n",
        "                          domain=\"variety.com\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"The movie was directed by Jane Smith and stars Tom Hanks.\",\n",
        "                          domain=\"imdb.com\", relevance_score=0.8, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The total number of fish in the ocean is 3.5 trillion.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"A 2015 study estimated there are about 3.5 trillion fish in the ocean.\",\n",
        "                          domain=\"nature.com\", relevance_score=0.9, published_at=OLD),\n",
        "            SourcePassage(content=\"It is impossible to get an exact count. This number is a rough estimate and highly debated.\",\n",
        "                          domain=\"noaa.gov\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Shakespeare's favorite food was apples.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"William Shakespeare was a playwright in the late 16th and early 17th centuries.\",\n",
        "                          domain=\"history.com\", relevance_score=0.8, published_at=OLD),\n",
        "            SourcePassage(content=\"Apples were a common food in Elizabethan England.\",\n",
        "                          domain=\"foodhistory.com\", relevance_score=0.7, published_at=RECENT),\n",
        "            SourcePassage(content=\"There are no surviving records or letters from Shakespeare that mention his personal food preferences.\",\n",
        "                          domain=\"shakespeare.org\", relevance_score=0.95, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The CEO of Google is a bad person.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The current CEO of Google is Sundar Pichai.\",\n",
        "                          domain=\"google.com\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"Google's stock price has increased under his leadership.\",\n",
        "                          domain=\"finance.com\", relevance_score=0.8, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"The Loch Ness Monster is female.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"The Loch Ness Monster is a creature from Scottish folklore, said to inhabit Loch Ness.\",\n",
        "                          domain=\"scotland.com\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"Since the creature's existence has not been proven, its sex is unknown.\",\n",
        "                          domain=\"cryptozoology.com\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Cats are native to Australia.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Feral cats are a major invasive species in Australia, threatening native wildlife.\",\n",
        "                          domain=\"environment.gov.au\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"Cats were introduced to Australia by European settlers in the 1800s.\",\n",
        "                          domain=\"history.com\", relevance_score=0.9, published_at=OLD),\n",
        "            SourcePassage(content=\"Australia's native mammals are primarily marsupials, like kangaroos and koalas.\",\n",
        "                          domain=\"natgeo.com\", relevance_score=0.8, published_at=RECENT),\n",
        "        ],\n",
        "        # Note: This could be \"Refuted\", but the claim is \"native\" and the passages\n",
        "        # imply \"not native\". Let's make it more clearly NEI by removing the refutation.\n",
        "        # Self-correction: The above example is \"Refuted\". Let's make a real NEI.\n",
        "        ground_truth_verdict=\"Not enough evidence\"\n",
        "    ),\n",
        "    GoldStandardExample(\n",
        "        claim=\"Cats are the most popular pet in Australia.\",\n",
        "        passages=[\n",
        "            SourcePassage(content=\"Australia has one of the highest rates of pet ownership in the world.\",\n",
        "                          domain=\"pets.au\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"Dogs are very popular in Australia, with 40% of households owning at least one.\",\n",
        "                          domain=\"rspca.org.au\", relevance_score=0.9, published_at=RECENT),\n",
        "            SourcePassage(content=\"Cats are also very popular, with 27% of households owning one.\",\n",
        "                          domain=\"rspca.org.au\", relevance_score=0.9, published_at=RECENT),\n",
        "        ],\n",
        "        ground_truth_verdict=\"Not enough evidence\" # The passages imply dogs are more popular, but don't state it\n",
        "    ),\n",
        "]\n",
        "print(f\"Generated a new dataset with {len(gold_standard_dataset)} examples.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- [NEW] Step 1.5: Split the dataset ---\n",
        "# Create a new list containing ONLY the 3 classes we want the model to learn.\n",
        "trainable_dataset = [\n",
        "    item for item in gold_standard_dataset\n",
        "    if item.ground_truth_verdict != \"Not enough evidence\"\n",
        "]\n",
        "\n",
        "NEI_dataset = [\n",
        "    item for item in gold_standard_dataset\n",
        "    if item.ground_truth_verdict == \"Not enough evidence\"\n",
        "]\n",
        "\n",
        "print(f\"Original dataset size: {len(gold_standard_dataset)}\")\n",
        "print(f\"Trainable (3-class) dataset size: {len(trainable_dataset)}\")\n",
        "\n",
        "# --- [MODIFIED] Step 1.5: Split the dataset ---\n",
        "\n",
        "# Get all labels for stratification FROM THE NEW LIST\n",
        "all_labels = [item.ground_truth_verdict for item in trainable_dataset]\n",
        "\n",
        "# Perform the split on the NEW LIST\n",
        "train_dataset, test_dataset = train_test_split(\n",
        "    trainable_dataset, # <-- Use the filtered dataset\n",
        "    test_size=0.25,\n",
        "    random_state=42,\n",
        "    stratify=all_labels\n",
        ")\n",
        "\n",
        "test_dataset.extend(NEI_dataset)\n",
        "\n",
        "print(f\"Training examples: {len(train_dataset)}\")\n",
        "print(f\"Test examples: {len(test_dataset)}\")\n",
        "\n",
        "print(f\"\\n--- Data Split ---\")\n",
        "print(f\"Total examples: {len(gold_standard_dataset)}\")\n",
        "\n",
        "\n",
        "# --- Step 2: Generate Training Data ---\n",
        "\n",
        "print(\"\\nGenerating training data from raw examples...\")\n",
        "\n",
        "# We need a validator instance *just* for data generation.\n",
        "# It needs the REAL NLI backend.\n",
        "nli = NLIModel(\n",
        "        emb_model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
        "        nli_model_name=\"roberta-large-mnli\",\n",
        "        nli_labels=NLI_LABELS\n",
        "    )\n",
        "data_gen_validator = FactValidator(\n",
        "    llm=None,\n",
        "    nli_backend=nli,\n",
        "    clf=None,\n",
        "    encoder=None\n",
        ")\n",
        "\n",
        "X_train_list = []\n",
        "y_labels = []\n",
        "\n",
        "# [!] MODIFIED: Iterate over the train_dataset only\n",
        "for i, item in enumerate(train_dataset):\n",
        "    # 1. Use the new method to process the raw text\n",
        "    features, num_a, num_d, len_v, len_p = data_gen_validator.generate_training_example(\n",
        "        item.claim, item.passages\n",
        "    )\n",
        "\n",
        "    # 2. Get the feature vector\n",
        "    feature_vector_1d = data_gen_validator._prepare_features(\n",
        "        features, num_a, num_d, len_v, len_p\n",
        "    )[0]\n",
        "\n",
        "    X_train_list.append(feature_vector_1d)\n",
        "\n",
        "    # 3. Store the corresponding ground truth label\n",
        "    y_labels.append(item.ground_truth_verdict)\n",
        "\n",
        "    print(f\"  Training Example {i+1} ({item.ground_truth_verdict}): Features={np.round(feature_vector_1d, 2)}\")\n",
        "\n",
        "# Convert to NumPy arrays for scikit-learn\n",
        "X_train = np.array(X_train_list)\n",
        "print(f\"\\nFeature matrix (X) shape: {X_train.shape}\")\n",
        "print(f\"Labels (y) to be encoded: {y_labels}\")\n",
        "\n",
        "# --- Step 3: Train the Encoder and Classifier ---\n",
        "\n",
        "# 1. Train the Label Encoder\n",
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_labels)\n",
        "\n",
        "print(f\"\\nEncoded labels: {y_train}\")\n",
        "print(f\"Encoder classes: {encoder.classes_}\")\n",
        "\n",
        "# 2. Train the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n--- Decision Tree Classifier Trained ---\")\n",
        "\n",
        "\n",
        "# --- Step 4: Use the Trained Models in a Production Validator ---\n",
        "\n",
        "print(\"\\nInstantiating new 'production' validator with trained models...\")\n",
        "\n",
        "production_validator = FactValidator(\n",
        "    llm=LLMInterface(),\n",
        "    nli_backend=nli,  # <-- Use your REAL NLI model here\n",
        "    clf=clf,\n",
        "    encoder=encoder\n",
        ")\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# --- Step 5: Test the New Validator and Collect Results ---\n",
        "print(\"\\n--- Testing the 'production' validator on UNSEEN test data ---\")\n",
        "\n",
        "# --- [NEW] Create lists to store all predictions ---\n",
        "y_true = [] # The ground truth labels\n",
        "y_pred = [] # The model's predicted labels\n",
        "\n",
        "correct_predictions = 0\n",
        "for i, test_example in enumerate(test_dataset):\n",
        "    # Run the full validation pipeline\n",
        "    result = production_validator.validate_claim(test_example.claim, test_example.passages)\n",
        "\n",
        "    expected = test_example.ground_truth_verdict\n",
        "    predicted = result.verdict\n",
        "\n",
        "    # --- [NEW] Add results to our lists ---\n",
        "    y_true.append(expected)\n",
        "    y_pred.append(predicted)\n",
        "\n",
        "    is_correct = (expected == predicted)\n",
        "    if is_correct:\n",
        "        correct_predictions += 1\n",
        "\n",
        "    print(f\"\\nTest Case {i+1}:\")\n",
        "    print(f\"  Claim: {test_example.claim[:50]}...\")\n",
        "    print(f\"  Expected: {expected}\")\n",
        "    print(f\"  Predicted: {predicted} (Score: {result.score})\")\n",
        "    print(f\"  Result: {'CORRECT' if is_correct else 'INCORRECT'}\")\n",
        "\n",
        "# --- [!] NEW: Step 6: Show Overall Accuracy and Detailed Report ---\n",
        "\n",
        "# 1. Calculate and print final accuracy\n",
        "accuracy = (correct_predictions / len(test_dataset)) * 100\n",
        "print(f\"\\n--- Test Summary ---\")\n",
        "print(f\"Overall Accuracy: {accuracy:.2f}% ({correct_predictions} / {len(test_dataset)} correct)\")\n",
        "\n",
        "# 2. Generate the detailed classification report\n",
        "print(\"\\n--- Detailed Classification Report ---\")\n",
        "\n",
        "# Define all possible labels in the order you want them\n",
        "all_verdicts = [\"Supported\", \"Refuted\", \"Contested\", \"Not enough evidence\"]\n",
        "\n",
        "# Print the report\n",
        "# - digits=3 gives you 3 decimal places\n",
        "# - zero_division=0 prevents warnings if a class is never predicted (precision=0)\n",
        "print(classification_report(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    labels=all_verdicts,\n",
        "    digits=3,\n",
        "    zero_division=0\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWbzvQdMvQzt",
        "outputId": "cd47dd2e-2b69-4ad4-c5fc-b8cea389e7cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset size: 101\n",
            "Trainable (3-class) dataset size: 75\n",
            "Training examples: 56\n",
            "Test examples: 45\n",
            "\n",
            "--- Data Split ---\n",
            "Total examples: 101\n",
            "\n",
            "Generating training data from raw examples...\n",
            "Initializing heavy models... This happens once.\n",
            "  Training Example 1 (Contested): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.]\n",
            "  Training Example 2 (Supported): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  Training Example 3 (Refuted): Features=[0.   0.   0.98 0.   0.97 1.   0.   0.   2.   2.   2.  ]\n",
            "  Training Example 4 (Contested): Features=[0.   0.   0.74 0.   0.9  1.   0.   0.   1.   1.   2.  ]\n",
            "  Training Example 5 (Refuted): Features=[0.   0.   0.97 0.   0.99 1.   0.   0.   1.   1.   1.  ]\n",
            "  Training Example 6 (Refuted): Features=[0.   0.   0.99 0.   0.98 1.   0.   0.   1.   1.   1.  ]\n",
            "  Training Example 7 (Contested): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.]\n",
            "  Training Example 8 (Supported): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  Training Example 9 (Refuted): Features=[0.   0.   0.99 0.   0.99 1.   0.   0.   1.   1.   1.  ]\n",
            "  Training Example 10 (Supported): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  Training Example 11 (Contested): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.]\n",
            "  Training Example 12 (Supported): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.]\n",
            "  Training Example 13 (Refuted): Features=[0.   0.   1.   0.   0.99 1.   0.   0.   1.   1.   1.  ]\n",
            "  Training Example 14 (Refuted): Features=[0.   0.   1.   0.   0.97 1.   0.   0.   2.   2.   2.  ]\n",
            "  Training Example 15 (Supported): Features=[0.72 0.72 0.   1.   0.99 1.   0.   1.   0.   1.   1.  ]\n",
            "  Training Example 16 (Refuted): Features=[0.   0.   1.   0.   0.99 1.   0.   0.   1.   1.   1.  ]\n",
            "  Training Example 17 (Refuted): Features=[0.   0.   0.99 0.   0.99 1.   0.   0.   1.   1.   1.  ]\n",
            "  Training Example 18 (Supported): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.]\n",
            "  Training Example 19 (Supported): Features=[0.99 0.99 0.   1.   0.99 1.   0.   1.   0.   1.   1.  ]\n",
            "  Training Example 20 (Contested): Features=[0.  0.  1.  0.  0.9 1.  0.  0.  1.  1.  2. ]\n",
            "  Training Example 21 (Supported): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  Training Example 22 (Supported): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  Training Example 23 (Contested): Features=[0.   0.   0.99 0.   0.9  0.3  0.   0.   1.   1.   2.  ]\n",
            "  Training Example 24 (Refuted): Features=[0.   0.   0.95 0.   0.99 1.   0.   0.   1.   1.   1.  ]\n",
            "  Training Example 25 (Contested): Features=[0.   0.   0.99 0.   0.9  1.   0.   0.   1.   1.   2.  ]\n",
            "  Training Example 26 (Contested): Features=[0.33 0.33 1.   0.   0.85 1.   0.33 0.   1.   2.   2.  ]\n",
            "  Training Example 27 (Contested): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.]\n",
            "  Training Example 28 (Refuted): Features=[0.   0.   1.   0.   0.99 1.   0.   0.   1.   1.   1.  ]\n",
            "  Training Example 29 (Supported): Features=[0.84 0.84 0.   1.   0.99 1.   0.   1.   0.   1.   1.  ]\n",
            "  Training Example 30 (Contested): Features=[0.   0.   0.76 0.   0.9  1.   0.   0.   1.   1.   2.  ]\n",
            "  Training Example 31 (Supported): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.]\n",
            "  Training Example 32 (Supported): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  Training Example 33 (Contested): Features=[0.   0.   0.89 0.   0.9  1.   0.   0.   1.   1.   2.  ]\n",
            "  Training Example 34 (Contested): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.]\n",
            "  Training Example 35 (Supported): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  Training Example 36 (Contested): Features=[0.   0.   0.52 0.   0.92 1.   0.   0.   0.   1.   2.  ]\n",
            "  Training Example 37 (Supported): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  Training Example 38 (Refuted): Features=[0.   0.   1.   0.   0.99 1.   0.   0.   1.   1.   1.  ]\n",
            "  Training Example 39 (Refuted): Features=[0.   0.   1.   0.   0.94 1.   0.   0.   2.   2.   2.  ]\n",
            "  Training Example 40 (Refuted): Features=[0.   0.   0.68 0.   0.99 1.   0.   0.   1.   1.   1.  ]\n",
            "  Training Example 41 (Refuted): Features=[0.   0.   0.99 0.   0.99 1.   0.   0.   1.   1.   1.  ]\n",
            "  Training Example 42 (Contested): Features=[0.   0.   0.97 0.   0.9  0.3  0.   0.   1.   1.   2.  ]\n",
            "  Training Example 43 (Contested): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.]\n",
            "  Training Example 44 (Refuted): Features=[0.   0.   1.   0.   0.94 1.   0.   0.   2.   2.   2.  ]\n",
            "  Training Example 45 (Supported): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  Training Example 46 (Refuted): Features=[0.   0.   1.   0.   0.99 1.   0.   0.   1.   1.   1.  ]\n",
            "  Training Example 47 (Supported): Features=[0.36 0.36 0.   0.   0.99 0.3  0.   0.   0.   1.   1.  ]\n",
            "  Training Example 48 (Contested): Features=[0.   0.   0.67 0.   0.95 1.   0.   0.   1.   1.   2.  ]\n",
            "  Training Example 49 (Contested): Features=[0.   0.   0.95 0.   0.9  1.   0.   0.   1.   1.   2.  ]\n",
            "  Training Example 50 (Supported): Features=[0.79 0.79 0.   1.   0.99 1.   0.   1.   0.   1.   1.  ]\n",
            "  Training Example 51 (Refuted): Features=[0.   0.   1.   0.   0.94 1.   0.   0.   2.   2.   2.  ]\n",
            "  Training Example 52 (Contested): Features=[0.  0.  1.  0.  0.9 1.  0.  0.  1.  1.  2. ]\n",
            "  Training Example 53 (Refuted): Features=[0.   0.   1.   0.   0.99 1.   0.   0.   1.   1.   1.  ]\n",
            "  Training Example 54 (Contested): Features=[0.   0.   0.48 0.   0.9  0.3  0.   0.   0.   1.   2.  ]\n",
            "  Training Example 55 (Refuted): Features=[0.   0.   1.   0.   0.99 1.   0.   0.   1.   1.   1.  ]\n",
            "  Training Example 56 (Supported): Features=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "\n",
            "Feature matrix (X) shape: (56, 11)\n",
            "Labels (y) to be encoded: ['Contested', 'Supported', 'Refuted', 'Contested', 'Refuted', 'Refuted', 'Contested', 'Supported', 'Refuted', 'Supported', 'Contested', 'Supported', 'Refuted', 'Refuted', 'Supported', 'Refuted', 'Refuted', 'Supported', 'Supported', 'Contested', 'Supported', 'Supported', 'Contested', 'Refuted', 'Contested', 'Contested', 'Contested', 'Refuted', 'Supported', 'Contested', 'Supported', 'Supported', 'Contested', 'Contested', 'Supported', 'Contested', 'Supported', 'Refuted', 'Refuted', 'Refuted', 'Refuted', 'Contested', 'Contested', 'Refuted', 'Supported', 'Refuted', 'Supported', 'Contested', 'Contested', 'Supported', 'Refuted', 'Contested', 'Refuted', 'Contested', 'Refuted', 'Supported']\n",
            "\n",
            "Encoded labels: [0 2 1 0 1 1 0 2 1 2 0 2 1 1 2 1 1 2 2 0 2 2 0 1 0 0 0 1 2 0 2 2 0 0 2 0 2\n",
            " 1 1 1 1 0 0 1 2 1 2 0 0 2 1 0 1 0 1 2]\n",
            "Encoder classes: ['Contested' 'Refuted' 'Supported']\n",
            "\n",
            "--- Decision Tree Classifier Trained ---\n",
            "\n",
            "Instantiating new 'production' validator with trained models...\n",
            "\n",
            "--- Testing the 'production' validator on UNSEEN test data ---\n",
            "\n",
            "Test Case 1:\n",
            "  Claim: The original name of Twitter was 'FriendStalker'....\n",
            "  Expected: Refuted\n",
            "  Predicted: Refuted (Score: 100)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 2:\n",
            "  Claim: Pineapple belongs on pizza....\n",
            "  Expected: Contested\n",
            "  Predicted: Contested (Score: 100)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 3:\n",
            "  Claim: The \"five-second rule\" is real....\n",
            "  Expected: Contested\n",
            "  Predicted: Contested (Score: 100)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 4:\n",
            "  Claim: All deserts are hot....\n",
            "  Expected: Refuted\n",
            "  Predicted: Refuted (Score: 100)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 5:\n",
            "  Claim: Whales are large fish....\n",
            "  Expected: Refuted\n",
            "  Predicted: Refuted (Score: 100)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 6:\n",
            "  Claim: The capital of Japan is Tokyo....\n",
            "  Expected: Supported\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 7:\n",
            "  Claim: Astrology accurately predicts personality traits....\n",
            "  Expected: Contested\n",
            "  Predicted: Refuted (Score: 100)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 8:\n",
            "  Claim: Tomatoes are vegetables....\n",
            "  Expected: Refuted\n",
            "  Predicted: Refuted (Score: 100)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 9:\n",
            "  Claim: The speed of sound is faster than the speed of lig...\n",
            "  Expected: Refuted\n",
            "  Predicted: Refuted (Score: 100)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 10:\n",
            "  Claim: Humans have only five senses....\n",
            "  Expected: Refuted\n",
            "  Predicted: Refuted (Score: 100)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 11:\n",
            "  Claim: Neil Armstrong was the first person to walk on the...\n",
            "  Expected: Supported\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 12:\n",
            "  Claim: Bill Gates co-founded Microsoft....\n",
            "  Expected: Supported\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 13:\n",
            "  Claim: Mount Kilimanjaro is in Tanzania....\n",
            "  Expected: Supported\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 14:\n",
            "  Claim: The currency of the United Kingdom is the Pound St...\n",
            "  Expected: Supported\n",
            "  Predicted: Supported (Score: 100)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 15:\n",
            "  Claim: Penguins are flightless birds....\n",
            "  Expected: Supported\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 16:\n",
            "  Claim: A college degree is necessary for a successful car...\n",
            "  Expected: Contested\n",
            "  Predicted: Contested (Score: 100)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 17:\n",
            "  Claim: Photosynthesis is the process plants use to make f...\n",
            "  Expected: Supported\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 18:\n",
            "  Claim: Self-driving cars will be common by 2030....\n",
            "  Expected: Contested\n",
            "  Predicted: Contested (Score: 100)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 19:\n",
            "  Claim: Julius Caesar was the first Emperor of Rome....\n",
            "  Expected: Contested\n",
            "  Predicted: Refuted (Score: 100)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 20:\n",
            "  Claim: Leonardo da Vinci was a nice person....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 21:\n",
            "  Claim: The best color to paint a living room is blue....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 22:\n",
            "  Claim: Life exists on Mars....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 23:\n",
            "  Claim: The new Tesla Roadster will be released in 2025....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Contested (Score: 100)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 24:\n",
            "  Claim: A specific person, 'John Smith', is 40 years old....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 25:\n",
            "  Claim: The stock market will go up tomorrow....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 26:\n",
            "  Claim: Ghosts are real....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Contested (Score: 100)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 27:\n",
            "  Claim: The lost city of Atlantis has been found....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Refuted (Score: 100)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 28:\n",
            "  Claim: This specific apple is delicious....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 29:\n",
            "  Claim: The Earth's core has stopped spinning....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 30:\n",
            "  Claim: Bigfoot has been captured....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Contested (Score: 100)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 31:\n",
            "  Claim: The politician Jane Doe is honest....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 32:\n",
            "  Claim: A new laptop model 'X' is the best for students....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 33:\n",
            "  Claim: The cure for baldness will be available next year....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Refuted (Score: 100)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 34:\n",
            "  Claim: Dogs are happier than cats....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 35:\n",
            "  Claim: The pyramids were built by aliens....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Contested (Score: 100)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 36:\n",
            "  Claim: It will rain in London next Tuesday....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 37:\n",
            "  Claim: The next president of the US will be from Texas....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Contested (Score: 100)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 38:\n",
            "  Claim: The average house price in the US will fall in 202...\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 39:\n",
            "  Claim: The new movie 'Space Wars 5' is good....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 40:\n",
            "  Claim: The total number of fish in the ocean is 3.5 trill...\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 41:\n",
            "  Claim: Shakespeare's favorite food was apples....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Contested (Score: 100)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 42:\n",
            "  Claim: The CEO of Google is a bad person....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Not enough evidence (Score: -1)\n",
            "  Result: CORRECT\n",
            "\n",
            "Test Case 43:\n",
            "  Claim: The Loch Ness Monster is female....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Contested (Score: 100)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 44:\n",
            "  Claim: Cats are native to Australia....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Contested (Score: 100)\n",
            "  Result: INCORRECT\n",
            "\n",
            "Test Case 45:\n",
            "  Claim: Cats are the most popular pet in Australia....\n",
            "  Expected: Not enough evidence\n",
            "  Predicted: Contested (Score: 100)\n",
            "  Result: INCORRECT\n",
            "\n",
            "--- Test Summary ---\n",
            "Overall Accuracy: 57.78% (26 / 45 correct)\n",
            "\n",
            "--- Detailed Classification Report ---\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "          Supported      1.000     0.143     0.250         7\n",
            "            Refuted      0.600     1.000     0.750         6\n",
            "          Contested      0.308     0.667     0.421         6\n",
            "Not enough evidence      0.714     0.577     0.638        26\n",
            "\n",
            "           accuracy                          0.578        45\n",
            "          macro avg      0.655     0.597     0.515        45\n",
            "       weighted avg      0.689     0.578     0.564        45\n",
            "\n"
          ]
        }
      ]
    }
  ]
}